---
title: RAG 是什么
date: 2025-10-20 17:09:27
categories: ["默认分类"]
tags: []
---

# RAG 是什么？为什么它成了大模型落地的“标配”？
![2025-10-20T09:09:12.png][1]
最近几年，RAG（Retrieval-Augmented Generation，检索增强生成）这个词几乎成了大模型落地项目的标配。无论是知识问答、文档助手，还是企业智能客服，都在说自己是“RAG 架构”。

简单来说，RAG 是一种让大语言模型具备“外部记忆”的方法。传统模型回答问题完全依赖训练参数，但训练数据有时效性，模型并不知道最新的业务或文档。而 RAG 的做法是——在生成答案前，先去知识库里检索相关信息，再让模型基于这些资料回答。这就像模型身边多了个“资料管理员”📚，让它能即时查阅、即时回答。

工作原理其实不复杂：
当我们提问时，系统会先用一个 **Embedding 模型**把问题向量化，然后去向量数据库（如 Milvus、Faiss、Elasticsearch 等）中找到最相似的文档片段。接着，这些片段会被拼进 prompt，一起传给大语言模型生成回答。这样模型既能保持语言能力，又能引用你提供的知识。


相比直接问模型，RAG 有三个明显好处：
1. 模型能回答“它原本不知道”的内容，比如公司内部政策、产品手册。
2. 回答更可信，不容易胡说八道（虽然还不能完全避免 🤔）。
3. 更新方便，只要改知识库，不用重新微调模型。

举个常见的例子：企业知识问答。过去，员工问“我们的审批流程是几步？”，得去翻文档。现在用 RAG，只要提前把文档分段嵌入数据库，员工提问后系统检索出相关段落，再交给模型生成一句自然的回答：“审批流程共三步，分别是…”。既快又准。

当然，RAG 不是万能的。检索粒度、向量质量、上下文拼接都很影响效果。段落太大找不准，太小又容易丢语义；**Embedding 模型**选不好，相似度也不准。实践中，“检索比生成更重要”几乎是金科玉律。

现在，很多团队在探索更聪明的 RAG，比如混合召回（向量+BM25）、Graph RAG（知识图谱增强）、多轮上下文记忆等。RAG 不再只是“查资料”，而是演化成一种能动态理解和整合知识的框架。

RAG 的意义在于——它让大模型真正具备“知识更新”能力，而不用重新训练。
对于企业来说，这是一条极具性价比的落地路线：
1. 数据自己掌控，
2. 模型灵活组合，
3. 系统能随时更新。

一句话总结：

> RAG 让模型不止会“说”，还能“查”与“懂”。


  [1]: https:///images/typecho//2025/10/790909958.png
